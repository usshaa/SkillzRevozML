{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis in Social Media\n",
    "This solution provides a basic framework for sentiment analysis on social media posts using different machine learning algorithms and an interactive UI for real-time classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Setup and Data Preprocessing\n",
    "\n",
    "First, make sure you have the necessary libraries installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.7/site-packages (8.1.0)\n",
      "Requirement already satisfied: imblearn in /opt/conda/lib/python3.7/site-packages (0.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/conda/lib/python3.7/site-packages (from ipywidgets) (0.1.4)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets) (7.11.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.7/site-packages (from ipywidgets) (4.3.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.7 in /opt/conda/lib/python3.7/site-packages (from ipywidgets) (4.0.8)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.7 in /opt/conda/lib/python3.7/site-packages (from ipywidgets) (3.0.8)\n",
      "Requirement already satisfied: imbalanced-learn in /opt/conda/lib/python3.7/site-packages (from imblearn) (0.12.3)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (45.1.0.post20200119)\n",
      "Requirement already satisfied: jedi>=0.10 in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (0.16.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (4.4.1)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.39)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (2.5.2)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.0)\n",
      "Requirement already satisfied: pexpect in /opt/conda/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.7/site-packages (from traitlets>=4.3.1->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from traitlets>=4.3.1->ipywidgets) (1.14.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (1.21.6)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (1.7.3)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (1.0.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (3.1.0)\n",
      "Requirement already satisfied: parso>=0.5.2 in /opt/conda/lib/python3.7/site-packages (from jedi>=0.10->ipython>=6.1.0->ipywidgets) (0.6.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.1.8)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.7/site-packages (from pexpect->ipython>=6.1.0->ipywidgets) (0.6.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from ipywidgets import widgets, HBox, VBox\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Data Setup:** We use a small sample dataset for demonstration purposes. In a real-world scenario, you would have a larger dataset of social media posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic text data\n",
    "def generate_synthetic_text_data(n_samples=1000):\n",
    "    sentiments = ['positive', 'neutral', 'negative']\n",
    "    text_data = []\n",
    "    sentiment_labels = []\n",
    "    \n",
    "    for _ in range(n_samples):\n",
    "        sentiment = np.random.choice(sentiments)\n",
    "        if sentiment == 'positive':\n",
    "            text = \" \".join([\"love\", \"great\", \"fantastic\", \"excellent\", \"good\", \"Azlina\"] * np.random.randint(1, 5))\n",
    "        elif sentiment == 'neutral':\n",
    "            text = \" \".join([\"okay\", \"fine\", \"average\", \"mediocre\", \"decent\"] * np.random.randint(1, 5))\n",
    "        else:\n",
    "            text = \" \".join([\"bad\", \"terrible\", \"awful\", \"horrible\", \"poor\"] * np.random.randint(1, 5))\n",
    "        \n",
    "        text_data.append(text)\n",
    "        sentiment_labels.append(sentiment)\n",
    "    \n",
    "    return text_data, sentiment_labels\n",
    "\n",
    "# Generate synthetic data\n",
    "texts, sentiments = generate_synthetic_text_data()\n",
    "\n",
    "# Create a DataFrame for easier handling\n",
    "df = pd.DataFrame({'text': texts, 'sentiment': sentiments})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>okay fine average mediocre decent okay fine av...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>love great fantastic excellent good Azlina lov...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>bad terrible awful horrible poor bad terrible ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>okay fine average mediocre decent okay fine av...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>love great fantastic excellent good Azlina</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text sentiment\n",
       "995  okay fine average mediocre decent okay fine av...   neutral\n",
       "996  love great fantastic excellent good Azlina lov...  positive\n",
       "997  bad terrible awful horrible poor bad terrible ...  negative\n",
       "998  okay fine average mediocre decent okay fine av...   neutral\n",
       "999         love great fantastic excellent good Azlina  positive"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Preprocessing and Vectorization:** We use TfidfVectorizer to convert text data into numerical format, removing English stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess and vectorize the text data\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000, ngram_range=(1, 2))\n",
    "X = vectorizer.fit_transform(df['text'])\n",
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Model Training:** We train KNN, Naive Bayes, and SVM classifiers on the preprocessed data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Interactive UI:** Using `ipywidgets`, we create an interactive interface where users can select a model and input text to classify its sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for KNN: {'n_neighbors': 3}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the classifiers\n",
    "# KNN with GridSearchCV\n",
    "param_grid = {'n_neighbors': [3, 5, 7, 9]}\n",
    "grid = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best parameters for KNN:\", grid.best_params_)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=grid.best_params_['n_neighbors'])\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train.toarray(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM\n",
    "svm = SVC(kernel='linear')\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to classify the sentiment\n",
    "def classify_sentiment(text, model):\n",
    "    text_vector = vectorizer.transform([text])\n",
    "    if model == nb:\n",
    "        prediction = model.predict(text_vector.toarray())\n",
    "    else:\n",
    "        prediction = model.predict(text_vector)\n",
    "    return prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the interactive UI\n",
    "def on_button_click(b):\n",
    "    model_name = model_widget.value\n",
    "    text = text_widget.value\n",
    "    if model_name == 'KNN':\n",
    "        model = knn\n",
    "    elif model_name == 'Naive Bayes':\n",
    "        model = nb\n",
    "    elif model_name == 'SVM':\n",
    "        model = svm\n",
    "    sentiment = classify_sentiment(text, model)\n",
    "    output.clear_output()\n",
    "    with output:\n",
    "        print(f'Sentiment: {sentiment}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55b8d856560043868cf516d7e3ec0be8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Model:', options=('KNN', 'Naive Bayes', 'SVM'), value='KNNâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the widgets\n",
    "model_widget = widgets.Dropdown(\n",
    "    options=['KNN', 'Naive Bayes', 'SVM'],\n",
    "    value='KNN',\n",
    "    description='Model:'\n",
    ")\n",
    "text_widget = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Type something...',\n",
    "    description='Text:'\n",
    ")\n",
    "button = widgets.Button(description=\"Classify\")\n",
    "button.on_click(on_button_click)\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "# Create the layout\n",
    "ui = VBox([HBox([model_widget, text_widget, button]), output])\n",
    "\n",
    "# Display the UI\n",
    "display(ui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1000x30 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 9739 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
