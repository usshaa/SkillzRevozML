{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic 5: **Data Normalization**\n",
    "\n",
    "Data normalization is the process of transforming data to conform to a specified range or distribution. This is often necessary to ensure that the data meets the assumptions of certain statistical methods or machine learning algorithms. Let's explore two common techniques for data normalization:\n",
    "\n",
    "### 1. Min-Max Scaling\n",
    "\n",
    "Min-max scaling rescales the data to a specified range, typically between 0 and 1. This technique is useful when the distribution of the data is approximately uniform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data:\n",
      "   Feature1\n",
      "0         1\n",
      "1         2\n",
      "2         3\n",
      "3         4\n",
      "4         5\n",
      "\n",
      "Scaled data using Min-Max Scaling:\n",
      "   Feature1\n",
      "0      0.00\n",
      "1      0.25\n",
      "2      0.50\n",
      "3      0.75\n",
      "4      1.00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Example data with numerical features\n",
    "data = pd.DataFrame({'Feature1': [1, 2, 3, 4, 5]})\n",
    "\n",
    "# Min-max scaling\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "data_scaled = pd.DataFrame(data_scaled, columns=data.columns)\n",
    "\n",
    "print(\"Original data:\")\n",
    "print(data)\n",
    "print(\"\\nScaled data using Min-Max Scaling:\")\n",
    "print(data_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Standardization (Z-score Scaling)\n",
    "\n",
    "Standardization rescales the data to have a mean of 0 and a standard deviation of 1. This technique is useful when the distribution of the data is approximately Gaussian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data:\n",
      "   Feature1\n",
      "0         1\n",
      "1         2\n",
      "2         3\n",
      "3         4\n",
      "4         5\n",
      "\n",
      "Scaled data using Z-score Scaling:\n",
      "   Feature1\n",
      "0 -1.414214\n",
      "1 -0.707107\n",
      "2  0.000000\n",
      "3  0.707107\n",
      "4  1.414214\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Example data with numerical features\n",
    "data = pd.DataFrame({'Feature1': [1, 2, 3, 4, 5]})\n",
    "\n",
    "# Z-score scaling\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "data_scaled = pd.DataFrame(data_scaled, columns=data.columns)\n",
    "\n",
    "print(\"Original data:\")\n",
    "print(data)\n",
    "print(\"\\nScaled data using Z-score Scaling:\")\n",
    "print(data_scaled)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
